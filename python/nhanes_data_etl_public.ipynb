{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b48761c-d2eb-46b5-8dae-fe5e7b0b67ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- dependencies\n",
    "import pandas as pd\n",
    "import pyreadstat\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b21be4f-e7a8-455c-9859-a6d5639b50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- defining paths as variables for all files needed (substitute with your local file paths)\n",
    "nhanes_ghb_path = r\"data\\raw\\NHANES_GHB_L_21-23.xpt\"\n",
    "nhanes_glu_path = r\"data\\raw\\NHANES_GLU_L_21-23.xpt\"\n",
    "nhanes_ins_path = r\"data\\raw\\NHANES_INS_L_21-23.xpt\"\n",
    "nhanes_demo_path = r\"data\\raw\\NHANES_DEMO_L_21-23.xpt\"\n",
    "nhanes_exam_path = r\"data\\raw\\NHANES_BMX_L_21-23.xpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bf0a4e5-c990-4cfe-a756-0bd22d91e9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- function to read xpt file and return df (with info to call)\n",
    "def read_xpt(path, df_name):\n",
    "    try:\n",
    "        df, meta = pyreadstat.read_xport(path)\n",
    "        globals()[df_name] = df\n",
    "        print(f\"DataFrame '{df_name} created successfully.\")\n",
    "    except UnicodeDecodeError as e:                                    # section added to handle unicode error in nhanes_demo dataset\n",
    "        print(f\"UnicodeDecodeError encountered: {e}\")\n",
    "        print(f\"... retrying with 'latin1' encoding...\")\n",
    "        try: \n",
    "            df, meta = pyreadstat.read_xport(path, encoding=\"latin1\")\n",
    "            globals()[df_name] = df\n",
    "            print(f\"DataFrame '{df_name} created successfully.\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Failed to read file with 'latin1' encoding: {e2}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {path}: {e}\")\n",
    "\n",
    "# call this function using:\n",
    "# path = nhanes_ghb_path\n",
    "# read_xpt(path, \"df_ghb\")\n",
    "# print(df_ghb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "600d78a4-58cf-47ba-b973-757a5085874f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'df_ghb created successfully.\n",
      "       seqn_id    ghb_weight  a1c_perc\n",
      "0     130378.0  56042.129410       5.6\n",
      "1     130379.0  37435.705647       5.6\n",
      "2     130380.0  85328.844519       6.2\n",
      "3     130386.0  44526.214135       5.1\n",
      "4     130387.0  22746.296353       5.9\n",
      "...        ...           ...       ...\n",
      "7194  142305.0  49710.929024       6.0\n",
      "7195  142307.0  68994.175834       6.2\n",
      "7196  142308.0      0.000000       NaN\n",
      "7197  142309.0  46284.416719       5.2\n",
      "7198  142310.0  53250.820372       5.3\n",
      "\n",
      "[7199 rows x 3 columns]\n",
      "DataFrame 'df_glu created successfully.\n",
      "       seqn_id  f_glucose_mgdl  fasting_weight\n",
      "0     130378.0           113.0   120025.308444\n",
      "1     130379.0            99.0        0.000000\n",
      "2     130380.0           156.0   145090.773569\n",
      "3     130386.0           100.0    82599.618089\n",
      "4     130394.0            88.0   100420.348913\n",
      "...        ...             ...             ...\n",
      "3991  142301.0           110.0    31123.370660\n",
      "3992  142303.0           160.0   109582.336415\n",
      "3993  142305.0           132.0    84790.011290\n",
      "3994  142308.0             NaN        0.000000\n",
      "3995  142309.0            96.0    75122.197301\n",
      "\n",
      "[3996 rows x 3 columns]\n",
      "DataFrame 'df_ins created successfully.\n",
      "       seqn_id  f_insulin_uuml\n",
      "0     130378.0           15.53\n",
      "1     130379.0           19.91\n",
      "2     130380.0           16.33\n",
      "3     130386.0           11.38\n",
      "4     130394.0            7.20\n",
      "...        ...             ...\n",
      "3991  142301.0            5.62\n",
      "3992  142303.0           17.09\n",
      "3993  142305.0           24.86\n",
      "3994  142308.0             NaN\n",
      "3995  142309.0            6.22\n",
      "\n",
      "[3996 rows x 2 columns]\n",
      "UnicodeDecodeError encountered: 'utf-8' codec can't decode byte 0x92 in position 13: invalid start byte\n",
      "... retrying with 'latin1' encoding...\n",
      "DataFrame 'df_demo created successfully.\n",
      "        seqn_id  age_yrs   demo_weight   exam_weight\n",
      "0      130378.0     43.0  50055.450807  54374.463898\n",
      "1      130379.0     66.0  29087.450605  34084.721548\n",
      "2      130380.0     44.0  80062.674301  81196.277992\n",
      "3      130381.0      5.0  38807.268902  55698.607106\n",
      "4      130382.0      2.0  30607.519774  36434.146346\n",
      "...         ...      ...           ...           ...\n",
      "11928  142306.0      9.0  11147.192563  13459.129019\n",
      "11929  142307.0     49.0  69419.620456  64962.328962\n",
      "11930  142308.0     50.0  32696.313477  44367.534132\n",
      "11931  142309.0     40.0  30547.974564  46249.361849\n",
      "11932  142310.0     80.0  32753.585494  49647.225467\n",
      "\n",
      "[11933 rows x 4 columns]\n",
      "DataFrame 'df_exam created successfully.\n",
      "       seqn_id  bmi_kg\n",
      "0     130378.0    27.0\n",
      "1     130379.0    33.5\n",
      "2     130380.0    29.7\n",
      "3     130381.0    23.8\n",
      "4     130382.0     NaN\n",
      "...        ...     ...\n",
      "8855  142306.0    15.4\n",
      "8856  142307.0     NaN\n",
      "8857  142308.0    26.4\n",
      "8858  142309.0    25.5\n",
      "8859  142310.0    27.6\n",
      "\n",
      "[8860 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# -- turning all files into dataframes & basic cleaning to only get desired fields\n",
    "\n",
    "# for the glycohemoglobin (a1c) data\n",
    "path = nhanes_ghb_path\n",
    "read_xpt(path, \"df_ghb\")\n",
    "df_ghb = df_ghb[['SEQN', 'WTPH2YR', 'LBXGH']]\n",
    "df_ghb = df_ghb.rename(columns={\n",
    "    'SEQN': 'seqn_id',\n",
    "    'LBXGH': 'a1c_perc', \n",
    "    'WTPH2YR': 'ghb_weight'\n",
    "    })\n",
    "print(df_ghb)\n",
    "\n",
    "# for the fasting glucose data\n",
    "path = nhanes_glu_path\n",
    "read_xpt(path, \"df_glu\")\n",
    "df_glu = df_glu[['SEQN', 'LBXGLU', 'WTSAF2YR']]\n",
    "df_glu = df_glu.rename(columns={\n",
    "    'SEQN': 'seqn_id',\n",
    "    'LBXGLU': 'f_glucose_mgdl',\n",
    "    'WTSAF2YR': 'fasting_weight'     # the same weight is used for both fasting glucose and fasting insulin\n",
    "    })\n",
    "print(df_glu)\n",
    "\n",
    "# for the insulin data\n",
    "path = nhanes_ins_path\n",
    "read_xpt(path, \"df_ins\")\n",
    "df_ins = df_ins[['SEQN', 'LBXIN']]\n",
    "df_ins = df_ins.rename(columns={\n",
    "    'SEQN': 'seqn_id',\n",
    "    'LBXIN': 'f_insulin_uuml',\n",
    "    })\n",
    "print(df_ins)\n",
    "\n",
    "# for the demographic (age) data\n",
    "path = nhanes_demo_path\n",
    "read_xpt(path, \"df_demo\")\n",
    "# df_demo = df_demo[['SEQN', 'RIDAGEYR', 'INDFMPIR', 'DMDEDUC2', 'WTINT2YR', 'WTMEC2YR']]       # optional / future\n",
    "df_demo = df_demo[['SEQN', 'RIDAGEYR', 'WTINT2YR', 'WTMEC2YR']]\n",
    "df_demo = df_demo.rename(columns={\n",
    "    'SEQN': 'seqn_id',\n",
    "    'RIDAGEYR': 'age_yrs',\n",
    "    # 'INDFMPIR': 'income_poverty_ratio',\n",
    "    # 'DMDEDUC2': 'edu_level',\n",
    "    'WTINT2YR': 'demo_weight',\n",
    "    'WTMEC2YR': 'exam_weight'       # the exam weight is stored with the demographic data\n",
    "    })\n",
    "print(df_demo)\n",
    "\n",
    "# for the exam (bmi) data\n",
    "path = nhanes_exam_path\n",
    "read_xpt(path, \"df_exam\")\n",
    "df_exam = df_exam[['SEQN', 'BMXBMI']]\n",
    "df_exam = df_exam.rename(columns={\n",
    "    'SEQN': 'seqn_id',\n",
    "    'BMXBMI': 'bmi_kg'\n",
    "    })\n",
    "print(df_exam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7c35c68-aec3-42a0-9df6-69b4a5bc3b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       seqn_id  a1c_perc  f_glucose_mgdl  f_insulin_uuml  age_yrs  bmi_kg  \\\n",
      "0     130378.0       5.6           113.0           15.53     43.0    27.0   \n",
      "1     130379.0       5.6            99.0           19.91     66.0    33.5   \n",
      "2     130380.0       6.2           156.0           16.33     44.0    29.7   \n",
      "3     130386.0       5.1           100.0           11.38     34.0    30.2   \n",
      "4     130394.0       4.8            88.0            7.20     51.0    24.4   \n",
      "...        ...       ...             ...             ...      ...     ...   \n",
      "3990  142300.0       5.1            95.0           10.35     46.0    32.6   \n",
      "3991  142301.0       5.6           110.0            5.62     80.0    30.5   \n",
      "3992  142303.0       8.1           160.0           17.09     69.0    27.9   \n",
      "3993  142305.0       6.0           132.0           24.86     76.0    26.4   \n",
      "3995  142309.0       5.2            96.0            6.22     40.0    25.5   \n",
      "\n",
      "        ghb_weight  fasting_weight   demo_weight   exam_weight  \n",
      "0     56042.129410   120025.308444  50055.450807  54374.463898  \n",
      "1     37435.705647        0.000000  29087.450605  34084.721548  \n",
      "2     85328.844519   145090.773569  80062.674301  81196.277992  \n",
      "3     44526.214135    82599.618089  30995.282610  39988.452940  \n",
      "4     52478.876664   100420.348913  41925.463225  51305.024430  \n",
      "...            ...             ...           ...           ...  \n",
      "3990  31470.681927    65949.198146  28399.611503  30517.128836  \n",
      "3991  17782.087977    31123.370660  11799.054910  17561.693314  \n",
      "3992  47778.604939   109582.336415  33250.569425  47087.576098  \n",
      "3993  49710.929024    84790.011290  28979.979165  43483.407534  \n",
      "3995  46284.416719    75122.197301  30547.974564  46249.361849  \n",
      "\n",
      "[3441 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# -- combining all of the dataframes into one & cleaning up\n",
    "# merging all (with seqn as key)\n",
    "combined_df = pd.merge(df_ghb, df_glu, on='seqn_id', how='inner')\n",
    "combined_df = pd.merge(combined_df, df_ins, on='seqn_id', how='inner')\n",
    "combined_df = pd.merge(combined_df, df_demo, on='seqn_id', how='inner')\n",
    "combined_df = pd.merge(combined_df, df_exam, on='seqn_id', how='inner')\n",
    "\n",
    "# reordering columns for readability \n",
    "combined_df = combined_df[['seqn_id','a1c_perc', 'f_glucose_mgdl', 'f_insulin_uuml', 'age_yrs', 'bmi_kg',\n",
    "                           'ghb_weight', 'fasting_weight', 'demo_weight', 'exam_weight']]\n",
    "\n",
    "# dropping nulls so that we are only looking at participants with all values \n",
    "combined_df = combined_df.dropna(subset=['a1c_perc'])\n",
    "combined_df = combined_df.dropna(subset=['f_glucose_mgdl'])\n",
    "combined_df = combined_df.dropna(subset=['f_insulin_uuml'])\n",
    "combined_df = combined_df.dropna(subset=['age_yrs'])\n",
    "combined_df = combined_df.dropna(subset=['bmi_kg'])\n",
    "\n",
    "# return df\n",
    "clean_df = combined_df\n",
    "print(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8332c25-60b2-473c-b8c8-e3855112a175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3441 entries, 0 to 3995\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   seqn_id         3441 non-null   float64\n",
      " 1   a1c_perc        3441 non-null   float64\n",
      " 2   f_glucose_mgdl  3441 non-null   float64\n",
      " 3   f_insulin_uuml  3441 non-null   float64\n",
      " 4   age_yrs         3441 non-null   float64\n",
      " 5   bmi_kg          3441 non-null   float64\n",
      " 6   ghb_weight      3441 non-null   float64\n",
      " 7   fasting_weight  3441 non-null   float64\n",
      " 8   demo_weight     3441 non-null   float64\n",
      " 9   exam_weight     3441 non-null   float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 295.7 KB\n",
      "Missing data ('0' values):  seqn_id             0\n",
      "a1c_perc            0\n",
      "f_glucose_mgdl      0\n",
      "f_insulin_uuml      0\n",
      "age_yrs             0\n",
      "bmi_kg              0\n",
      "ghb_weight          0\n",
      "fasting_weight    285\n",
      "demo_weight         0\n",
      "exam_weight         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# reviewing \n",
    "# clean_df.describe()      # reviewing basic stats for each column\n",
    "clean_df.info()          # gives number of non-null values \n",
    "\n",
    "# check columns for '0' values (this validation could find '0' values that indicate missing data but were not dropped with the nulls)\n",
    "# the NHANES documentation indicates that all of our core data (a1c, glucose, insulin, age, and bmi) is free of '0' values (but the weights are not) \n",
    "total_zeros = (clean_df == 0).sum()\n",
    "print(\"Missing data ('0' values): \", total_zeros)\n",
    "\n",
    "# -- rationale / notes  \n",
    "# we only want to use the records that have all core values AND the selected weight (and we have not selected a weight yet) \n",
    "# ... so, e.g., if we utilize a weight with any '0' values, we need to also filter those records out (as they will not represent total pop) \n",
    "# ... looks like fasting_weight has a number of '0' values, despite having recorded values for both glucose and insulin (& we dropped nulls above ^) \n",
    "# ... the documentation says that a '0' for this weight (WTSAF2YR) means \"No Lab Result or Not Fasting for 8 to <24 hours\" ...\n",
    "# ... so it seems like survey administrators identified/removed folks from fasting pop weight who had fasting tests done (for one reason or another)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e96ee952-61e6-47fe-ad9c-dd7ddc0dc8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of filtered records (core data):  3441\n",
      "Count of ghb_weight:  6750\n",
      "Percent filtered ghb_weight:  0.49\n",
      "Count of fasting_weight:  3361\n",
      "Percent filtered fasting_weight:  0.061\n",
      "Count of demo_weight:  11933\n",
      "Percent filtered demo_weight:  0.712\n",
      "Count of exam_weight:  8860\n",
      "Percent filtered exam_weight:  0.612\n",
      "The best weight for normalization is the smallest percentage loss from original after filtering:  0.061\n"
     ]
    }
   ],
   "source": [
    "# -- evaluate the population weights to see which is the best fit for normalization\n",
    "    # the NHANES documentation indicates that, when combining datasets, a single weight should be used, and it should be the most restrictive\n",
    "    # ... so we want to consider which of the original weights has the most overlap with our filtered data \n",
    "    # ... which means we need to calculate the count of population weights from each original dataframe for comparison (and scale up to the sum)\n",
    "    # (the NHANES documentation does present the total records with/without missing values, but we will show/validate the calculations here) \n",
    "\n",
    "# -- count of records from our new filtered dataframe\n",
    "# (this is the number we have filtered down to - need to normalize the weights based on this!)\n",
    "count_filtered = clean_df['seqn_id'].shape[0]\n",
    "print(\"Count of filtered records (core data): \", count_filtered)\n",
    "\n",
    "# -- counts of population weights from each original dataframe\n",
    "# (checking the count of weights that have values greater than 0 will exclude any missing or null values)\n",
    "# ghb weight\n",
    "count_ghb = df_ghb[(df_ghb['ghb_weight'] > 0)].shape[0]\n",
    "print(\"Count of ghb_weight: \", count_ghb)\n",
    "diff_ghb = round(((count_ghb - count_filtered) / count_ghb), 3)\n",
    "print(\"Percent filtered ghb_weight: \", diff_ghb)\n",
    "\n",
    "# fasting weight\n",
    "count_fasting = df_glu[(df_glu['fasting_weight'] > 0)].shape[0]\n",
    "print(\"Count of fasting_weight: \", count_fasting)\n",
    "diff_fasting = round(((count_fasting - (count_filtered - 285)) / count_fasting), 3)    # added -285 to remove the '0' records that would need to be filtered out\n",
    "print(\"Percent filtered fasting_weight: \", diff_fasting)\n",
    "\n",
    "# demo weight\n",
    "count_demo = df_demo[(df_demo['demo_weight'] > 0)].shape[0]\n",
    "print(\"Count of demo_weight: \", count_demo)\n",
    "diff_demo = round(((count_demo - count_filtered) / count_demo), 3)\n",
    "print(\"Percent filtered demo_weight: \", diff_demo)\n",
    "\n",
    "# exam weight\n",
    "count_exam = df_demo[(df_demo['exam_weight'] > 0)].shape[0]\n",
    "print(\"Count of exam_weight: \", count_exam)\n",
    "diff_exam = round(((count_exam - count_filtered) / count_exam), 3)\n",
    "print(\"Percent filtered exam_weight: \", diff_exam)\n",
    "\n",
    "# -- find minimum weight\n",
    "best_weight = min(diff_ghb, diff_fasting, diff_demo, diff_exam)\n",
    "print(\"The best weight for normalization is the smallest percentage loss from original after filtering: \", best_weight)\n",
    "\n",
    "# summary: normalizing to fasting_weight will only result in 6.1% loss of records from original weight count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2397d31-d880-4116-8f84-85fe3b004158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Population:  279992595.93949234\n",
      "Filtered Weight Sum:  264249300.74824518\n",
      "Scale Factor:  1.0595774336835277\n",
      "Normalized Fasting Weight Sum:  279992595.93949234\n",
      "       seqn_id  a1c_perc  f_glucose_mgdl  f_insulin_uuml  age_yrs  bmi_kg  \\\n",
      "0     130378.0       5.6           113.0           15.53     43.0    27.0   \n",
      "2     130380.0       6.2           156.0           16.33     44.0    29.7   \n",
      "3     130386.0       5.1           100.0           11.38     34.0    30.2   \n",
      "4     130394.0       4.8            88.0            7.20     51.0    24.4   \n",
      "6     130396.0       5.0           104.0            4.11     56.0    27.3   \n",
      "...        ...       ...             ...             ...      ...     ...   \n",
      "3990  142300.0       5.1            95.0           10.35     46.0    32.6   \n",
      "3991  142301.0       5.6           110.0            5.62     80.0    30.5   \n",
      "3992  142303.0       8.1           160.0           17.09     69.0    27.9   \n",
      "3993  142305.0       6.0           132.0           24.86     76.0    26.4   \n",
      "3995  142309.0       5.2            96.0            6.22     40.0    25.5   \n",
      "\n",
      "      normalized_weight  \n",
      "0         127176.108298  \n",
      "2         153734.909509  \n",
      "3          87520.691358  \n",
      "4         106403.135591  \n",
      "6          84949.802321  \n",
      "...                 ...  \n",
      "3990       69878.282125  \n",
      "3991       32977.621211  \n",
      "3992      116110.970795  \n",
      "3993       89841.582565  \n",
      "3995       79597.785029  \n",
      "\n",
      "[3156 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# -- adding a new, normalized weight based on the filtered core data\n",
    "\n",
    "# drop records where fasting_weight equal to 0\n",
    "cleaning_df = clean_df[clean_df['fasting_weight'] != 0].copy()\n",
    "\n",
    "# calculate the sum of the fasting weight in the filtered data\n",
    "filtered_weight_sum = cleaning_df['fasting_weight'].sum()\n",
    "\n",
    "# get total population using original fasting_weight (before filtered to core data)\n",
    "# since no records dropped from this value yet, and it includes all lab participants, this sum is best view of total population \n",
    "total_population_sum = df_glu['fasting_weight'].sum()\n",
    "\n",
    "# factor to scale up filtered weight\n",
    "scale_factor = total_population_sum / filtered_weight_sum\n",
    "\n",
    "# calc normalized weight (scale the filtered fasting weight to be proportionate to the total population from original fasting weight)\n",
    "cleaning_df['normalized_weight'] = cleaning_df['fasting_weight'] * scale_factor\n",
    "\n",
    "# drop unneeded weights\n",
    "cleaned_df = cleaning_df.drop(columns=['ghb_weight', 'demo_weight', 'exam_weight' \n",
    "                                  , 'fasting_weight'                                                # optional, keep to review\n",
    "                                 ])\n",
    "\n",
    "# rename the dataframe before load\n",
    "normalized_df = cleaned_df\n",
    "\n",
    "# print results\n",
    "print(\"Total Population: \", total_population_sum)\n",
    "print(\"Filtered Weight Sum: \", filtered_weight_sum)\n",
    "print(\"Scale Factor: \", scale_factor)\n",
    "print(\"Normalized Fasting Weight Sum: \", normalized_df['normalized_weight'].sum())\n",
    "print(normalized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b95002-d142-4c17-8a38-ec1de7cd2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       seqn_id  a1c_perc  f_glucose_mgdl  f_insulin_uuml  age_yrs  bmi_kg  \\\n",
      "0     130378.0       5.6           113.0           15.53     43.0    27.0   \n",
      "2     130380.0       6.2           156.0           16.33     44.0    29.7   \n",
      "3     130386.0       5.1           100.0           11.38     34.0    30.2   \n",
      "4     130394.0       4.8            88.0            7.20     51.0    24.4   \n",
      "6     130396.0       5.0           104.0            4.11     56.0    27.3   \n",
      "...        ...       ...             ...             ...      ...     ...   \n",
      "3990  142300.0       5.1            95.0           10.35     46.0    32.6   \n",
      "3991  142301.0       5.6           110.0            5.62     80.0    30.5   \n",
      "3992  142303.0       8.1           160.0           17.09     69.0    27.9   \n",
      "3993  142305.0       6.0           132.0           24.86     76.0    26.4   \n",
      "3995  142309.0       5.2            96.0            6.22     40.0    25.5   \n",
      "\n",
      "      normalized_weight a1c_threshold   homa_ir     insulin_sensitivity  \\\n",
      "0         127176.108298        normal  4.333062  significant resistance   \n",
      "2         153734.909509   prediabetes  6.290074  significant resistance   \n",
      "3          87520.691358        normal  2.809877        early resistance   \n",
      "4         106403.135591        normal  1.564444      normal sensitivity   \n",
      "6          84949.802321        normal  1.055407      normal sensitivity   \n",
      "...                 ...           ...       ...                     ...   \n",
      "3990       69878.282125        normal  2.427778        early resistance   \n",
      "3991       32977.621211        normal  1.526420      normal sensitivity   \n",
      "3992      116110.970795      diabetes  6.751605  significant resistance   \n",
      "3993       89841.582565   prediabetes  8.102519  significant resistance   \n",
      "3995       79597.785029        normal  1.474370      normal sensitivity   \n",
      "\n",
      "             age_cohort       bmi_threshold  \n",
      "0        40 to 50 years       C: overweight  \n",
      "2        40 to 50 years       C: overweight  \n",
      "3        30 to 40 years  D: obesity class 1  \n",
      "4        50 to 60 years    B: normal weight  \n",
      "6        50 to 60 years       C: overweight  \n",
      "...                 ...                 ...  \n",
      "3990     40 to 50 years  D: obesity class 1  \n",
      "3991  80 years or older  D: obesity class 1  \n",
      "3992     60 to 70 years       C: overweight  \n",
      "3993     70 to 80 years       C: overweight  \n",
      "3995     40 to 50 years       C: overweight  \n",
      "\n",
      "[3156 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# -- adding in calculations to indicate health or severity of lab results\n",
    "\n",
    "# interpreting a1c_perc according to a1c thresholds\n",
    "def interpret_a1c(a1c):\n",
    "    if a1c < 5.7:\n",
    "        return 'normal'\n",
    "    elif 5.7 <= a1c < 6.5:\n",
    "        return 'prediabetes'\n",
    "    elif a1c >= 6.5:\n",
    "        return 'diabetes'\n",
    "    else: \n",
    "        return 'unknown'\n",
    "\n",
    "normalized_df['a1c_threshold'] = normalized_df['a1c_perc'].apply(interpret_a1c)\n",
    "\n",
    "# calculating and interpreting insulin sensitivity using HOMA-IR formula\n",
    "normalized_df['homa_ir'] = (normalized_df['f_glucose_mgdl'] * normalized_df['f_insulin_uuml']) / 405\n",
    "\n",
    "def interpret_homa(homa_ir):\n",
    "    if homa_ir < 2.0:                     # could add 'heightened sensitivity' as less than 1, but this is simple and consistent with a1c thresholds\n",
    "        return 'normal sensitivity'\n",
    "    elif 2.0 <= homa_ir < 3.0:\n",
    "        return 'early resistance'\n",
    "    elif homa_ir >= 3.0:\n",
    "        return 'significant resistance'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "normalized_df['insulin_sensitivity'] = normalized_df['homa_ir'].apply(interpret_homa)\n",
    "\n",
    "# cohorting by age group (decade intervals)\n",
    "def age_cohort(age):\n",
    "    if 0 <= age < 12:\n",
    "        return '12 years or less'\n",
    "    elif 12 <= age < 20:\n",
    "        return '12 to 20 years'\n",
    "    elif 20 <= age < 30:\n",
    "        return '20 to 30 years'\n",
    "    elif 30 <= age < 40:\n",
    "        return '30 to 40 years'\n",
    "    elif 40 <= age < 50:\n",
    "        return '40 to 50 years'\n",
    "    elif 50 <= age < 60:\n",
    "        return '50 to 60 years'\n",
    "    elif 60 <= age < 70:\n",
    "        return '60 to 70 years'\n",
    "    elif 70 <= age < 80:\n",
    "        return '70 to 80 years'\n",
    "    elif age >= 80:\n",
    "        return '80 years or older'        # NHANES records all participants over 80 as just '80' \n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "normalized_df['age_cohort'] = normalized_df['age_yrs'].apply(age_cohort)\n",
    "\n",
    "# interpreting BMI u\n",
    "def interpret_bmi(bmi):\n",
    "    if bmi < 18.5:\n",
    "        return 'A: underweight'\n",
    "    elif 18.5 <= bmi < 25:\n",
    "        return 'B: normal weight'\n",
    "    elif 25 <= bmi < 30:\n",
    "        return 'C: overweight'\n",
    "    elif 30 <= bmi < 35:\n",
    "        return 'D: obesity class 1'\n",
    "    elif 35 <= bmi < 40:\n",
    "        return 'E: obesity class 2'\n",
    "    elif bmi >= 40:\n",
    "        return 'F: extreme obesity class 3'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "normalized_df['bmi_threshold'] = normalized_df['bmi_kg'].apply(interpret_bmi)\n",
    "\n",
    "\n",
    "nhanes_all = normalized_df\n",
    "# print(normalized_df)\n",
    "print(nhanes_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8461e435-9f61-4a7a-878c-8189a02b117f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       seqn_id  a1c_perc a1c_threshold   homa_ir     insulin_sensitivity  \\\n",
      "0     130378.0       5.6        normal  4.333062  significant resistance   \n",
      "2     130380.0       6.2   prediabetes  6.290074  significant resistance   \n",
      "3     130386.0       5.1        normal  2.809877        early resistance   \n",
      "4     130394.0       4.8        normal  1.564444      normal sensitivity   \n",
      "6     130396.0       5.0        normal  1.055407      normal sensitivity   \n",
      "...        ...       ...           ...       ...                     ...   \n",
      "3990  142300.0       5.1        normal  2.427778        early resistance   \n",
      "3991  142301.0       5.6        normal  1.526420      normal sensitivity   \n",
      "3992  142303.0       8.1      diabetes  6.751605  significant resistance   \n",
      "3993  142305.0       6.0   prediabetes  8.102519  significant resistance   \n",
      "3995  142309.0       5.2        normal  1.474370      normal sensitivity   \n",
      "\n",
      "      age_yrs         age_cohort  bmi_kg       bmi_threshold  \\\n",
      "0        43.0     40 to 50 years    27.0       C: overweight   \n",
      "2        44.0     40 to 50 years    29.7       C: overweight   \n",
      "3        34.0     30 to 40 years    30.2  D: obesity class 1   \n",
      "4        51.0     50 to 60 years    24.4    B: normal weight   \n",
      "6        56.0     50 to 60 years    27.3       C: overweight   \n",
      "...       ...                ...     ...                 ...   \n",
      "3990     46.0     40 to 50 years    32.6  D: obesity class 1   \n",
      "3991     80.0  80 years or older    30.5  D: obesity class 1   \n",
      "3992     69.0     60 to 70 years    27.9       C: overweight   \n",
      "3993     76.0     70 to 80 years    26.4       C: overweight   \n",
      "3995     40.0     40 to 50 years    25.5       C: overweight   \n",
      "\n",
      "      normalized_weight     total_pop  \n",
      "0         127176.108298  2.799926e+08  \n",
      "2         153734.909509  2.799926e+08  \n",
      "3          87520.691358  2.799926e+08  \n",
      "4         106403.135591  2.799926e+08  \n",
      "6          84949.802321  2.799926e+08  \n",
      "...                 ...           ...  \n",
      "3990       69878.282125  2.799926e+08  \n",
      "3991       32977.621211  2.799926e+08  \n",
      "3992      116110.970795  2.799926e+08  \n",
      "3993       89841.582565  2.799926e+08  \n",
      "3995       79597.785029  2.799926e+08  \n",
      "\n",
      "[3156 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# optional\n",
    "# drop columns that won't be needed, reorder the existing columns, add a static total_population column for easier analysis \n",
    "nhanes_final = nhanes_all.drop(columns = ['f_glucose_mgdl', 'f_insulin_uuml'])\n",
    "nhanes_final = nhanes_final[['seqn_id', 'a1c_perc', 'a1c_threshold', 'homa_ir', 'insulin_sensitivity', \n",
    "                             'age_yrs', 'age_cohort', 'bmi_kg', 'bmi_threshold', 'normalized_weight']]\n",
    "nhanes_final['total_pop'] = total_population_sum \n",
    "\n",
    "print(nhanes_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4863315-2162-4f23-8137-3edf1ce978cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqn_id</th>\n",
       "      <th>a1c_perc</th>\n",
       "      <th>homa_ir</th>\n",
       "      <th>age_yrs</th>\n",
       "      <th>bmi_kg</th>\n",
       "      <th>normalized_weight</th>\n",
       "      <th>total_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3156.000000</td>\n",
       "      <td>3.156000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>136376.736692</td>\n",
       "      <td>5.700729</td>\n",
       "      <td>4.007540</td>\n",
       "      <td>49.643536</td>\n",
       "      <td>29.224588</td>\n",
       "      <td>88717.552579</td>\n",
       "      <td>2.799926e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3453.024305</td>\n",
       "      <td>1.015061</td>\n",
       "      <td>9.398656</td>\n",
       "      <td>20.167995</td>\n",
       "      <td>7.447206</td>\n",
       "      <td>65852.953095</td>\n",
       "      <td>5.961409e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>130378.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.066543</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>12141.892446</td>\n",
       "      <td>2.799926e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>133389.750000</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.470667</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>44043.536821</td>\n",
       "      <td>2.799926e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>136401.500000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.436741</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>69787.883312</td>\n",
       "      <td>2.799926e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139351.250000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>4.098883</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>33.100000</td>\n",
       "      <td>111879.235148</td>\n",
       "      <td>2.799926e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>142309.000000</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>227.243704</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>74.800000</td>\n",
       "      <td>595400.325846</td>\n",
       "      <td>2.799926e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             seqn_id     a1c_perc      homa_ir      age_yrs       bmi_kg  \\\n",
       "count    3156.000000  3156.000000  3156.000000  3156.000000  3156.000000   \n",
       "mean   136376.736692     5.700729     4.007540    49.643536    29.224588   \n",
       "std      3453.024305     1.015061     9.398656    20.167995     7.447206   \n",
       "min    130378.000000     3.200000     0.066543    12.000000    14.000000   \n",
       "25%    133389.750000     5.200000     1.470667    33.000000    24.000000   \n",
       "50%    136401.500000     5.500000     2.436741    53.000000    27.900000   \n",
       "75%    139351.250000     5.800000     4.098883    66.000000    33.100000   \n",
       "max    142309.000000    13.700000   227.243704    80.000000    74.800000   \n",
       "\n",
       "       normalized_weight     total_pop  \n",
       "count        3156.000000  3.156000e+03  \n",
       "mean        88717.552579  2.799926e+08  \n",
       "std         65852.953095  5.961409e-08  \n",
       "min         12141.892446  2.799926e+08  \n",
       "25%         44043.536821  2.799926e+08  \n",
       "50%         69787.883312  2.799926e+08  \n",
       "75%        111879.235148  2.799926e+08  \n",
       "max        595400.325846  2.799926e+08  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- reviewing finalized data \n",
    "# nhanes_all.describe()\n",
    "# nhanes_all.info()\n",
    "\n",
    "nhanes_final.describe()\n",
    "# nhanes_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2d56e79-b061-4d4f-bb55-f121c81daa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- data loading dependencies\n",
    "from sqlalchemy import create_engine\n",
    "# import os\n",
    "import pyodbc\n",
    "import psycopg2\n",
    "\n",
    "# -- database connection\n",
    "pad = 'postgres'\n",
    "uid = 'postgres'\n",
    "server = 'localhost'\n",
    "\n",
    "# -- loading data\n",
    "def load_data(df):\n",
    "    try:\n",
    "        rows_imported = 0\n",
    "        len_df = len(df)\n",
    "        engine = create_engine(f'postgresql://{uid}:{pad}@{server}:{port}/{database_name}')\n",
    "        print(f'importing rows {rows_imported} to {rows_imported + len_df}... for table')\n",
    "        df.to_sql(table_name, engine, if_exists='replace', index=False) # creates table\n",
    "        rows_imported += len_df\n",
    "        print(\"data imported successfully ðŸš€\")\n",
    "    except Exception as e:\n",
    "        print(\"data load error: \" + str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e6b91-7ea5-4f40-8c02-8af518f29fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- loading the data (final_df)\n",
    "uid = 'postgres'                # db username\n",
    "pad = 'postgres'                # password for user\n",
    "server = 'localhost'            # host/server address, localhost if local\n",
    "port = '5432'                   # port (usually 5432)\n",
    "database_name = 'postgres'      # database name \n",
    "# ------------------------- \n",
    "table_name = 'nhanes_data'      # new table name\n",
    "load_data(nhanes_final)         # dataframe to load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
